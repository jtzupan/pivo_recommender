{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivo Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking for a new way to compare and recommend beer.  \n",
    "\n",
    "This notebook scrapes beer reviews from [BeerAdvocate](https://www.beeradvocate.com/) then performs natural language processing on these reviews.  Once a profile of a beer has been created, a similar, semi-similar, or completely different beer can be recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/johnzupan/mystuff/pivo_rec'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd beerAdvocateScraper\n",
    "%scrapy crawl reviewScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrase Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrase modeling is an approach to learning combinations of tokens that together represent meaning multi-word concepts.  These phrase models are developed by looping over the words in the corpus and finding words that appear together more than they should by random chance.  The formula used to determine if whether two tokens $A$ and $B$ constitute a phrase is:\n",
    "\n",
    "$$\n",
    "\\frac {count(A B) - count_{min}}\n",
    "{count(A) * count(B)}\n",
    "*N > threshold\n",
    "$$\n",
    "\n",
    "where:\n",
    "* $count(A)$ is the number of times $A$ appears in the corpus\n",
    "* $count(B)$ is the number of times $B$ appears in the corpus\n",
    "* $count(AB)$ is the number of times $AB$ appear in the corpus in that order\n",
    "* $N$ is the total size of the corpus vocabulary\n",
    "* $count_{min}$ is a user-defined parameter to ensure that the phrase appears a minimum number of times\n",
    "* $threshold$ is a user-defined paramter to control how strong the relationship must be before the two tokens are considered a single concept\n",
    "\n",
    "Once we have trained the phrase model we can apply it to the reviews in our corpus.  It will consider the multiworded tokens to be single phrases.\n",
    "\n",
    "The gensim library will help us with phrase modeling, specifically the Phrases class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mv beerAdvocateScraper/beerAdvocateScraper/BeerAdvocateReviews.csv ./intermediate/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile('^[\\d,\"]+')\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    with open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            try:\n",
    "                yield re.split(pattern, review)[1].replace('\\\\n', '\\n')\n",
    "            except: pass\n",
    "            if count % 1000 == 0:\n",
    "                print(f'on review {count}')\n",
    "            count += 1\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename),\n",
    "                                  batch_size=1000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intermediate_directory = os.path.join('.', 'intermediate')\n",
    "# review_txt_filepath = os.path.join(intermediate_directory,'BeerAdvocateReviews.csv')\n",
    "review_txt_filepath = os.path.join(intermediate_directory,'slimReviews.csv')\n",
    "ngram_all = os.path.join(intermediate_directory, 'ngram_all')\n",
    "unigram_sentences_filepath = os.path.join(ngram_all,\n",
    "                                          'unigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `lemmatized_sentence_corpus` generator to loop over the original review text, segmenting the reviews into individual sentences and normalizing the text.  We will write this data back out to a new file (`unigram_sentence_all`), with one normalized sentence per line.  We will use this data for learning our phrase models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on review 0\n",
      "black and thick\n",
      "tan head\n",
      "nose be perfect with huge maple syrup and coffee\n",
      "bourbon and vanilla\n",
      "good breakfast ever\n",
      "taste maple vanilla bourbon and oak\n",
      "everything -PRON- want in a beer\n",
      "not overly roasted\n",
      "just perfect\n",
      "full bodied\n",
      "good carbonation\n",
      "end with maple syrup\n",
      "amazing\n",
      "that be all\n",
      "can not believe -PRON- live up to the hype\n",
      "oz\n",
      "bottle pour into a snifter\n",
      "no bottle number\n",
      "appearance inky black\n",
      "stain the glass again\n",
      "big and dark head than mornin delight and assassin\n",
      "great surface wisps\n",
      "smell bourbon\n",
      "maple\n",
      "vanilla\n",
      "dark chocolate\n",
      "everything -PRON- would want in a stout\n",
      "the bourbon do take over though\n",
      "taste bourbon be sharp\n",
      "coffee come out here\n",
      "dark chocolate\n",
      "maple come out in the back\n",
      "sweetness linger\n",
      "bourbon flavor linger also\n",
      "mouthfeel very thick\n",
      "boozy\n",
      "sweet with medium carbonation\n",
      "overall tough to argue which be good but bourbon always win\n",
      "serve alongside mornin delight and assassin\n",
      "the beer be near black with a filmy beige head\n",
      "all hype and bias aside this aroma be silly good\n",
      "oak roast coffee vanilla\n",
      "world class from the first sip\n",
      "the definition of grace and balance\n",
      "silky smooth on the palate\n",
      "absolutely amazing\n",
      "review from note from 1/1/14a- bottle of 300 whatev that mean\n",
      "pour into -PRON- topple goliath snifter -PRON- be black as a moonless starless night\n",
      "-PRON- be thick and viscous with a medium sized brown head that slowly recede to a tan collar that leave some lace\n",
      "s-\n",
      "the aroma be nearly identical to the base beer but with bourbon and oak as well\n",
      "ton of burn sugar black strap molass coffee and bitter baker 's chocolate\n",
      "licorice vanilla sweet buttery bourbon rich dark chocolate and some burn alcohol\n",
      "smell incredible!t- wham\n",
      "-PRON- just get smack in the face with awesome\n",
      "the flavor deliver above and beyond the aroma and the base beer\n",
      "-PRON- have all the sweetness from the base but -PRON- be temper and mellow by the bourbon and oak\n",
      "the chocolate burn sugar molass coffee and vanilla all come together in a complex melange of flavor\n",
      "while flavor wise -PRON- may slightly prefer double barrel damon this be perfect in -PRON- be own way!m-\n",
      "the mouth feel be spot on\n",
      "thick viscous mouth coating yet with ample carbonation\n",
      "o-\n",
      "what can -PRON- say\n",
      "topple goliath have deliver one of if not the good ba stout in the world\n",
      "just incredible all around\n",
      "many thank to patrick for share this at -PRON- birthday tasting\n",
      "a like black coffee very slight head leave minimal leg on the side of the glasss maple syrup maple syrup and more maple syrup lot of bourbon barrel slight bourbon st slight coffee and chocolate\n",
      "do -PRON- mention maple syrup?t\n",
      "maple syrup coffee chocolate not as much bourbon taste but slightly hot bourbon st taste like a candy maple chocolate candy dip in a mocha lot of coffee aftertaste that linger on the tongue along with a slight bourbon st amazingm sweet without be cloy\n",
      "well carbedo\n",
      "if -PRON- be a perfect world everyone would have multiple of this and drink one now and age one\n",
      "on one hand all the flavor be there and well balanced\n",
      "however six month would smooth out that slight hotness and temper the maple syrup\n",
      "small nit one of the good beer -PRON- have have\n",
      "dark body black with brown highlight\n",
      "viscous glass stain alcohol leg\n",
      "extremely short lived head\n",
      "marshmallow vanilla smell\n",
      "maple become apparent after a sip\n",
      "maple dominate\n",
      "roasty\n",
      "barrel presence and coffee be there\n",
      "but like -PRON- say maple\n",
      "would put this at about 13.5%abv if -PRON- have to guess\n",
      "nice and thick mouthfeel\n",
      "low perfect carbonation point\n",
      "after have both this and mornin delight -PRON- will say that i like -PRON- close to equally\n",
      "the maple aspect of this guy be a little overbearing cbs wish -PRON- have that presence though\n",
      "thank 4daloveofstout for the most hype value whatev beer -PRON- have have to this point\n",
      "-PRON- be not one to get on hype train about beer\n",
      "buuuutt\n",
      "this beer live up to -PRON- hype\n",
      "thick dark molass type consisitency pour with little head\n",
      "smell of coffee and maple syrup\n",
      "taste like a coffee brownie\n",
      "and about as thick as one\n",
      "incredible beer\n",
      "2014 super balance\n",
      "pours out black as night\n",
      "coffee lot of maple syrup bitter dark chocolate roasted malt and sweetness\n",
      "get some boozy heat and bitterness on the back end\n",
      "coat the mouth\n",
      "no doubt this be world class but -PRON- feel like -PRON- have have this before\n",
      "the beer pour out extremely dark black like motor oil\n",
      "the aroma shoot out of the bottle even a couple foot away as one pour -PRON- out\n",
      "there be big chocolate roasted coffee huge caramel and molass sweetness and whiskey\n",
      "the aroma be very well integrate of complexity\n",
      "the flavor follow with huge chunky milk chocolate surround by a medium roast earthy coffee and medium minus note of whiskey\n",
      "the beer transition onto a big dark caramel sweetness with mocha coffee a hint of berry fruit on the finish\n",
      "the mouthfeel be thick and luscious\n",
      "just a beautifully craft barrel aged brew\n",
      "nothing really jump out aggressive with a harmony of whiskey medium minus barrel note coffee chocolate and caramel sweetness\n"
     ]
    }
   ],
   "source": [
    "with open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "    for sentence in lemmatized_sentence_corpus(review_txt_filepath):\n",
    "        print(sentence)\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data in the `unigram_sentences_all` file is now organized as a large text file with one sentence per line.  This format allows us to use gensim's LineSentence class, a convenient iterator for working with gensim's other components.  It *streams* the documents/sentences from disk, so you never have to hold the entire corpus in RAM at once.  This allows you to scale the modeling to a very large corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste maple vanilla bourbon and oak\n",
      " \n",
      "everything -PRON- want in a beer\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for unigram_sentence in it.islice(unigram_sentences, 5,7):\n",
    "    print(u' '.join(unigram_sentence))\n",
    "    print(u' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_model_file = os.path.join(ngram_all, 'bigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    phrases = Phrases(unigram_sentences)\n",
    "    bigram_model = Phraser(phrases)\n",
    "    bigram_model.save(bigram_model_file)\n",
    "    \n",
    "bigram_model = Phrases.load(bigram_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = os.path.join(ngram_all,'bigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for unigram_sentence in unigram_sentences:\n",
    "\n",
    "        bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "\n",
    "        f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taste maple vanilla bourbon and oak\n",
      "\n",
      "everything -PRON- want in a beer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bigram_sentence in it.islice(bigram_sentences, 5, 7):\n",
    "    print(u' '.join(bigram_sentence))\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model_filepath = os.path.join(ngram_all, 'trigram_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "\n",
    "    phrases_trigram = Phrases(bigram_sentences)\n",
    "    trigram_model = Phraser(phrases_trigram)\n",
    "    trigram_model.save(trigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 1==1:\n",
    "    phrases = Phrases(unigram_sentences)\n",
    "    bigram_model = Phraser(phrases)\n",
    "    bigram_model.save(bigram_model_file)\n",
    "    \n",
    "bigram_model = Phrases.load(bigram_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(ngram_all, 'trigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for bigram_sentence in bigram_sentences:\n",
    "\n",
    "        trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "\n",
    "        f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bourbon and vanilla\n",
      "\n",
      "good breakfast ever\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trigram_sentence in it.islice(trigram_sentences, 3, 5):\n",
    "    print(u' '.join(trigram_sentence))\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_reviews_filepath = os.path.join(intermediate_directory,\n",
    "                                        'trigram_transformed_reviews_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on review 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for parsed_review in nlp.pipe(line_review(review_txt_filepath),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "\n",
    "        # lemmatize the text, removing punctuation and whitespace\n",
    "        unigram_review = [token.lemma_ for token in parsed_review\n",
    "                          if not punct_space(token)]\n",
    "\n",
    "        # apply the first-order and second-order phrase models\n",
    "        bigram_review = bigram_model[unigram_review]\n",
    "        trigram_review = trigram_model[bigram_review]\n",
    "\n",
    "        # remove any remaining stopwords\n",
    "        trigram_review = [term for term in trigram_review\n",
    "                          if term not in STOP_WORDS]\n",
    "        \n",
    "        # remove pronouns\n",
    "        trigram_review = [term for term in trigram_review\n",
    "                          if term !='-PRON-']\n",
    "        \n",
    "\n",
    "        # write the transformed review as a line in the new file\n",
    "        trigram_review = u' '.join(trigram_review)\n",
    "        f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "on review 0\n",
      "Served alongside Mornin' Delight and Assassin. The beer is near black with a filmy beige head. All hype and bias aside, this aroma is silly good. Oak, roast, coffee, vanilla. World class from the first sip. The definition of grace and balance. Silky smooth on the palate. Absolutely amazing.\"\n",
      "\n",
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "78820\n",
      "serve alongside mornin delight assassin beer near black filmy beige head hype bias aside aroma silly good oak roast coffee vanilla world class sip definition grace balance silky smooth palate absolutely amazing\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <generator object line_review at 0x11c281db0>\n",
      "RuntimeError: generator ignored GeneratorExit\n",
      "Exception ignored in: <generator object get_beerID at 0x11c281db0>\n",
      "RuntimeError: generator ignored GeneratorExit\n"
     ]
    }
   ],
   "source": [
    "print(u'Original:' + u'\\n')\n",
    "\n",
    "for review in it.islice(line_review(review_txt_filepath), 2, 3):\n",
    "    print(review)\n",
    "\n",
    "print(u'----' + u'\\n')\n",
    "print(u'Transformed:' + u'\\n')\n",
    "\n",
    "with open(trigram_reviews_filepath, encoding='utf_8') as f:\n",
    "    for review in it.islice(f, 2, 3):\n",
    "#         for id in it.islice(get_beerID(review_txt_filepath),2,3):\n",
    "            print(id)\n",
    "            print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beerID(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    with open(review_txt_filepath, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            try:\n",
    "                yield re.split('(^[\\d\"]+)', review)[1].replace('\\\\n', '\\n')\n",
    "            except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of *word vector embedding models*, or *word vector models* for short is to learn dense numerical representations of each term in a corpus vocabulary.  If the model is succesful, the vectors it learns should encode some information about the *meaning* or *concept* the term represents, and the relationship between it and other terms in the vocabulary.  Word vector models are fully unsupervised &mdash; they learn all of these meaning and relationships solely by analyzing the text of the corpus, without any advanced knowledge provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# run with or without stop words removed and word lemmatized\n",
    "trigram_sentences = LineSentence(trigram_reviews_filepath)\n",
    "# trigram_sentences = LineSentence(trigram_sentences_filepath)\n",
    "word2vec_filepath = os.path.join(intermediate_directory, 'word2vec_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model for 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "if 1==1:\n",
    "    \n",
    "    # initiate the model and perform one epoch of training\n",
    "    beer2vec = Word2Vec(trigram_sentences, size=100, window=5,\n",
    "                       min_count=1, sg=1) #workers=?\n",
    "    beer2vec.save(word2vec_filepath)\n",
    "    \n",
    "    #perform the next n epochs of training\n",
    "    for i in range(1, 5):\n",
    "        beer2vec.train(trigram_sentences, total_examples=beer2vec.corpus_count, epochs=2)\n",
    "        beer2vec.save(word2vec_filepath)\n",
    "        \n",
    "        \n",
    "#load the finished model from disk\n",
    "beer2vec = Word2Vec.load(word2vec_filepath)\n",
    "beer2vec.init_sims()\n",
    "\n",
    "print(f'Trained model for {beer2vec.train_count} epochs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.097096</td>\n",
       "      <td>-0.077724</td>\n",
       "      <td>0.213747</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.096958</td>\n",
       "      <td>-0.033022</td>\n",
       "      <td>-0.101030</td>\n",
       "      <td>0.237131</td>\n",
       "      <td>-0.145274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175268</td>\n",
       "      <td>-0.139448</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>-0.154654</td>\n",
       "      <td>-0.006476</td>\n",
       "      <td>-0.022580</td>\n",
       "      <td>-0.099448</td>\n",
       "      <td>-0.069665</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.216365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourbon</th>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.094473</td>\n",
       "      <td>-0.073777</td>\n",
       "      <td>0.211184</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.088473</td>\n",
       "      <td>-0.024167</td>\n",
       "      <td>-0.102111</td>\n",
       "      <td>0.239401</td>\n",
       "      <td>-0.150555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170733</td>\n",
       "      <td>-0.134100</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>-0.158621</td>\n",
       "      <td>-0.011447</td>\n",
       "      <td>-0.011696</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>-0.064788</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.224218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.091595</td>\n",
       "      <td>-0.082576</td>\n",
       "      <td>0.209546</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>0.098617</td>\n",
       "      <td>-0.025143</td>\n",
       "      <td>-0.097095</td>\n",
       "      <td>0.235295</td>\n",
       "      <td>-0.144275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169356</td>\n",
       "      <td>-0.138224</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.152854</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>-0.093416</td>\n",
       "      <td>-0.074486</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.220004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.074859</td>\n",
       "      <td>0.215875</td>\n",
       "      <td>0.021551</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>-0.033044</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>0.244431</td>\n",
       "      <td>-0.138483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167888</td>\n",
       "      <td>-0.134354</td>\n",
       "      <td>-0.016564</td>\n",
       "      <td>-0.157530</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-0.100736</td>\n",
       "      <td>-0.067297</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.220440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.095586</td>\n",
       "      <td>-0.078170</td>\n",
       "      <td>0.215958</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>-0.033580</td>\n",
       "      <td>-0.088818</td>\n",
       "      <td>0.240017</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169262</td>\n",
       "      <td>-0.143153</td>\n",
       "      <td>-0.020515</td>\n",
       "      <td>-0.156416</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.022687</td>\n",
       "      <td>-0.102088</td>\n",
       "      <td>-0.073409</td>\n",
       "      <td>-0.010287</td>\n",
       "      <td>0.222813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maple_syrup</th>\n",
       "      <td>0.023244</td>\n",
       "      <td>0.101782</td>\n",
       "      <td>-0.083169</td>\n",
       "      <td>0.215741</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>0.098567</td>\n",
       "      <td>-0.022170</td>\n",
       "      <td>-0.104239</td>\n",
       "      <td>0.245453</td>\n",
       "      <td>-0.135163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166706</td>\n",
       "      <td>-0.146910</td>\n",
       "      <td>-0.018001</td>\n",
       "      <td>-0.154330</td>\n",
       "      <td>-0.004767</td>\n",
       "      <td>-0.024507</td>\n",
       "      <td>-0.105899</td>\n",
       "      <td>-0.076941</td>\n",
       "      <td>-0.014044</td>\n",
       "      <td>0.223670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maple</th>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.090412</td>\n",
       "      <td>-0.081401</td>\n",
       "      <td>0.215012</td>\n",
       "      <td>0.023898</td>\n",
       "      <td>0.087188</td>\n",
       "      <td>-0.021745</td>\n",
       "      <td>-0.094199</td>\n",
       "      <td>0.244242</td>\n",
       "      <td>-0.148566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176696</td>\n",
       "      <td>-0.147416</td>\n",
       "      <td>-0.024721</td>\n",
       "      <td>-0.155693</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>-0.015902</td>\n",
       "      <td>-0.093868</td>\n",
       "      <td>-0.069291</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>0.227276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark</th>\n",
       "      <td>0.007636</td>\n",
       "      <td>0.088682</td>\n",
       "      <td>-0.069289</td>\n",
       "      <td>0.220537</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>-0.022818</td>\n",
       "      <td>-0.090563</td>\n",
       "      <td>0.230376</td>\n",
       "      <td>-0.132074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178352</td>\n",
       "      <td>-0.145875</td>\n",
       "      <td>-0.016402</td>\n",
       "      <td>-0.159323</td>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.015554</td>\n",
       "      <td>-0.104589</td>\n",
       "      <td>-0.080708</td>\n",
       "      <td>-0.008988</td>\n",
       "      <td>0.229114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thick</th>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.101507</td>\n",
       "      <td>-0.065484</td>\n",
       "      <td>0.216440</td>\n",
       "      <td>0.029358</td>\n",
       "      <td>0.080772</td>\n",
       "      <td>-0.027001</td>\n",
       "      <td>-0.097177</td>\n",
       "      <td>0.243524</td>\n",
       "      <td>-0.133762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162760</td>\n",
       "      <td>-0.130723</td>\n",
       "      <td>-0.010028</td>\n",
       "      <td>-0.151420</td>\n",
       "      <td>-0.002267</td>\n",
       "      <td>-0.023116</td>\n",
       "      <td>-0.103739</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>-0.011244</td>\n",
       "      <td>0.217321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>head</th>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>-0.066684</td>\n",
       "      <td>0.222662</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.097836</td>\n",
       "      <td>-0.034139</td>\n",
       "      <td>-0.097054</td>\n",
       "      <td>0.241401</td>\n",
       "      <td>-0.138868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173682</td>\n",
       "      <td>-0.138941</td>\n",
       "      <td>-0.011796</td>\n",
       "      <td>-0.153245</td>\n",
       "      <td>-0.006603</td>\n",
       "      <td>-0.019848</td>\n",
       "      <td>-0.092079</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.009687</td>\n",
       "      <td>0.227955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4         5   \\\n",
       "coffee       0.012028  0.097096 -0.077724  0.213747  0.023751  0.096958   \n",
       "bourbon      0.006706  0.094473 -0.073777  0.211184  0.021388  0.088473   \n",
       "chocolate    0.015707  0.091595 -0.082576  0.209546  0.029002  0.098617   \n",
       "beer         0.008668  0.093705 -0.074859  0.215875  0.021551  0.093600   \n",
       "black        0.017581  0.095586 -0.078170  0.215958  0.026647  0.085226   \n",
       "maple_syrup  0.023244  0.101782 -0.083169  0.215741  0.032382  0.098567   \n",
       "maple        0.018604  0.090412 -0.081401  0.215012  0.023898  0.087188   \n",
       "dark         0.007636  0.088682 -0.069289  0.220537  0.033120  0.093210   \n",
       "thick        0.005687  0.101507 -0.065484  0.216440  0.029358  0.080772   \n",
       "head         0.012661  0.090200 -0.066684  0.222662  0.028686  0.097836   \n",
       "\n",
       "                   6         7         8         9     ...           90  \\\n",
       "coffee      -0.033022 -0.101030  0.237131 -0.145274    ...    -0.175268   \n",
       "bourbon     -0.024167 -0.102111  0.239401 -0.150555    ...    -0.170733   \n",
       "chocolate   -0.025143 -0.097095  0.235295 -0.144275    ...    -0.169356   \n",
       "beer        -0.033044 -0.096184  0.244431 -0.138483    ...    -0.167888   \n",
       "black       -0.033580 -0.088818  0.240017 -0.138578    ...    -0.169262   \n",
       "maple_syrup -0.022170 -0.104239  0.245453 -0.135163    ...    -0.166706   \n",
       "maple       -0.021745 -0.094199  0.244242 -0.148566    ...    -0.176696   \n",
       "dark        -0.022818 -0.090563  0.230376 -0.132074    ...    -0.178352   \n",
       "thick       -0.027001 -0.097177  0.243524 -0.133762    ...    -0.162760   \n",
       "head        -0.034139 -0.097054  0.241401 -0.138868    ...    -0.173682   \n",
       "\n",
       "                   91        92        93        94        95        96  \\\n",
       "coffee      -0.139448 -0.022495 -0.154654 -0.006476 -0.022580 -0.099448   \n",
       "bourbon     -0.134100 -0.015045 -0.158621 -0.011447 -0.011696 -0.092141   \n",
       "chocolate   -0.138224 -0.015839 -0.152854 -0.003384 -0.015999 -0.093416   \n",
       "beer        -0.134354 -0.016564 -0.157530 -0.009302 -0.022340 -0.100736   \n",
       "black       -0.143153 -0.020515 -0.156416 -0.000201 -0.022687 -0.102088   \n",
       "maple_syrup -0.146910 -0.018001 -0.154330 -0.004767 -0.024507 -0.105899   \n",
       "maple       -0.147416 -0.024721 -0.155693 -0.012190 -0.015902 -0.093868   \n",
       "dark        -0.145875 -0.016402 -0.159323 -0.014324 -0.015554 -0.104589   \n",
       "thick       -0.130723 -0.010028 -0.151420 -0.002267 -0.023116 -0.103739   \n",
       "head        -0.138941 -0.011796 -0.153245 -0.006603 -0.019848 -0.092079   \n",
       "\n",
       "                   97        98        99  \n",
       "coffee      -0.069665 -0.008444  0.216365  \n",
       "bourbon     -0.064788 -0.016234  0.224218  \n",
       "chocolate   -0.074486 -0.005449  0.220004  \n",
       "beer        -0.067297 -0.012181  0.220440  \n",
       "black       -0.073409 -0.010287  0.222813  \n",
       "maple_syrup -0.076941 -0.014044  0.223670  \n",
       "maple       -0.069291 -0.005753  0.227276  \n",
       "dark        -0.080708 -0.008988  0.229114  \n",
       "thick       -0.060929 -0.011244  0.217321  \n",
       "head        -0.068473 -0.009687  0.227955  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# build a list of the terms, integer indices,\n",
    "# and term counts from the food2vec model vocabulary\n",
    "ordered_vocab = [(term, voc.index, voc.count)\n",
    "                 for term, voc in beer2vec.wv.vocab.items()]\n",
    "\n",
    "# sort by the term counts, so the most common terms appear first\n",
    "ordered_vocab = sorted(ordered_vocab, key=lambda tup: -1*tup[-1])\n",
    "\n",
    "# # unzip the terms, integer indices, and counts into separate lists\n",
    "ordered_terms, term_indices, term_counts = zip(*ordered_vocab)\n",
    "\n",
    "# # create a DataFrame with the food2vec vectors as data,\n",
    "# # and the terms as row labels\n",
    "word_vectors = pd.DataFrame(beer2vec.wv.syn0norm[term_indices, :],\n",
    "                            index=ordered_terms)\n",
    "\n",
    "word_vectors.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction Using t-SNE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-Distributed Stochastic Neighbor Embedding, or *t-SNE*, is a dimensionality reduction technique to assist with visualizing high-dimensional datasets.  It attempts to map high-dimensional data onto a low (2 or 3) dimensional  representation such that the relative distance between points are preserved as closely as possible in both high and low dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "tsneInput = word_vectors.drop(STOP_WORDS, errors=u'ignore')\n",
    "tsneInput = tsneInput.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.097096</td>\n",
       "      <td>-0.077724</td>\n",
       "      <td>0.213747</td>\n",
       "      <td>0.023751</td>\n",
       "      <td>0.096958</td>\n",
       "      <td>-0.033022</td>\n",
       "      <td>-0.101030</td>\n",
       "      <td>0.237131</td>\n",
       "      <td>-0.145274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175268</td>\n",
       "      <td>-0.139448</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>-0.154654</td>\n",
       "      <td>-0.006476</td>\n",
       "      <td>-0.022580</td>\n",
       "      <td>-0.099448</td>\n",
       "      <td>-0.069665</td>\n",
       "      <td>-0.008444</td>\n",
       "      <td>0.216365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourbon</th>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.094473</td>\n",
       "      <td>-0.073777</td>\n",
       "      <td>0.211184</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.088473</td>\n",
       "      <td>-0.024167</td>\n",
       "      <td>-0.102111</td>\n",
       "      <td>0.239401</td>\n",
       "      <td>-0.150555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170733</td>\n",
       "      <td>-0.134100</td>\n",
       "      <td>-0.015045</td>\n",
       "      <td>-0.158621</td>\n",
       "      <td>-0.011447</td>\n",
       "      <td>-0.011696</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>-0.064788</td>\n",
       "      <td>-0.016234</td>\n",
       "      <td>0.224218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>0.015707</td>\n",
       "      <td>0.091595</td>\n",
       "      <td>-0.082576</td>\n",
       "      <td>0.209546</td>\n",
       "      <td>0.029002</td>\n",
       "      <td>0.098617</td>\n",
       "      <td>-0.025143</td>\n",
       "      <td>-0.097095</td>\n",
       "      <td>0.235295</td>\n",
       "      <td>-0.144275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169356</td>\n",
       "      <td>-0.138224</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.152854</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.015999</td>\n",
       "      <td>-0.093416</td>\n",
       "      <td>-0.074486</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.220004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.093705</td>\n",
       "      <td>-0.074859</td>\n",
       "      <td>0.215875</td>\n",
       "      <td>0.021551</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>-0.033044</td>\n",
       "      <td>-0.096184</td>\n",
       "      <td>0.244431</td>\n",
       "      <td>-0.138483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167888</td>\n",
       "      <td>-0.134354</td>\n",
       "      <td>-0.016564</td>\n",
       "      <td>-0.157530</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>-0.022340</td>\n",
       "      <td>-0.100736</td>\n",
       "      <td>-0.067297</td>\n",
       "      <td>-0.012181</td>\n",
       "      <td>0.220440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.017581</td>\n",
       "      <td>0.095586</td>\n",
       "      <td>-0.078170</td>\n",
       "      <td>0.215958</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.085226</td>\n",
       "      <td>-0.033580</td>\n",
       "      <td>-0.088818</td>\n",
       "      <td>0.240017</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169262</td>\n",
       "      <td>-0.143153</td>\n",
       "      <td>-0.020515</td>\n",
       "      <td>-0.156416</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.022687</td>\n",
       "      <td>-0.102088</td>\n",
       "      <td>-0.073409</td>\n",
       "      <td>-0.010287</td>\n",
       "      <td>0.222813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5   \\\n",
       "coffee     0.012028  0.097096 -0.077724  0.213747  0.023751  0.096958   \n",
       "bourbon    0.006706  0.094473 -0.073777  0.211184  0.021388  0.088473   \n",
       "chocolate  0.015707  0.091595 -0.082576  0.209546  0.029002  0.098617   \n",
       "beer       0.008668  0.093705 -0.074859  0.215875  0.021551  0.093600   \n",
       "black      0.017581  0.095586 -0.078170  0.215958  0.026647  0.085226   \n",
       "\n",
       "                 6         7         8         9     ...           90  \\\n",
       "coffee    -0.033022 -0.101030  0.237131 -0.145274    ...    -0.175268   \n",
       "bourbon   -0.024167 -0.102111  0.239401 -0.150555    ...    -0.170733   \n",
       "chocolate -0.025143 -0.097095  0.235295 -0.144275    ...    -0.169356   \n",
       "beer      -0.033044 -0.096184  0.244431 -0.138483    ...    -0.167888   \n",
       "black     -0.033580 -0.088818  0.240017 -0.138578    ...    -0.169262   \n",
       "\n",
       "                 91        92        93        94        95        96  \\\n",
       "coffee    -0.139448 -0.022495 -0.154654 -0.006476 -0.022580 -0.099448   \n",
       "bourbon   -0.134100 -0.015045 -0.158621 -0.011447 -0.011696 -0.092141   \n",
       "chocolate -0.138224 -0.015839 -0.152854 -0.003384 -0.015999 -0.093416   \n",
       "beer      -0.134354 -0.016564 -0.157530 -0.009302 -0.022340 -0.100736   \n",
       "black     -0.143153 -0.020515 -0.156416 -0.000201 -0.022687 -0.102088   \n",
       "\n",
       "                 97        98        99  \n",
       "coffee    -0.069665 -0.008444  0.216365  \n",
       "bourbon   -0.064788 -0.016234  0.224218  \n",
       "chocolate -0.074486 -0.005449  0.220004  \n",
       "beer      -0.067297 -0.012181  0.220440  \n",
       "black     -0.073409 -0.010287  0.222813  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsneInput.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_filepath = os.path.join(intermediate_directory,\n",
    "                             u'tsne_model')\n",
    "\n",
    "tsne_vectors_filepath = os.path.join(intermediate_directory,\n",
    "                                     u'tsne_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsneInput.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    \n",
    "    tsne = TSNE()\n",
    "    tsne_vectors = tsne.fit_transform(tsneInput.values)\n",
    "    \n",
    "    with open(tsne_filepath, 'wb') as f:\n",
    "        pickle.dump(tsne, f)\n",
    "\n",
    "    pd.np.save(tsne_vectors_filepath, tsne_vectors)\n",
    "    \n",
    "with open(tsne_filepath, 'rb') as f:\n",
    "    tsne = pickle.load(f)\n",
    "    \n",
    "tsne_vectors = pd.np.load(tsne_vectors_filepath)\n",
    "\n",
    "tsne_vectors = pd.DataFrame(tsne_vectors,\n",
    "                            index=pd.Index(tsneInput.index),\n",
    "                            columns=[u'x_coord', u'y_coord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_vectors[u'word'] = tsne_vectors.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>-65.032639</td>\n",
       "      <td>28.823454</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bourbon</th>\n",
       "      <td>59.224350</td>\n",
       "      <td>21.084337</td>\n",
       "      <td>bourbon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chocolate</th>\n",
       "      <td>-16.854601</td>\n",
       "      <td>-95.139938</td>\n",
       "      <td>chocolate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beer</th>\n",
       "      <td>-57.379971</td>\n",
       "      <td>104.477707</td>\n",
       "      <td>beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>83.488785</td>\n",
       "      <td>92.597794</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             x_coord     y_coord       word\n",
       "coffee    -65.032639   28.823454     coffee\n",
       "bourbon    59.224350   21.084337    bourbon\n",
       "chocolate -16.854601  -95.139938  chocolate\n",
       "beer      -57.379971  104.477707       beer\n",
       "black      83.488785   92.597794      black"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
